# Temporary script to convert Hads observation data (.tif) generated by Ruth's R
# script to 360-day-per-year format. The script also renames the files to match the
# names in the file names in the "Processed/HadsUKgrid/resampled_2.2km" folder and saves them
# in .nc format (same as the original Hads format in "Processed/HadsUKgrid/resampled_2.2km")

import os
import xarray as xr
import glob
import numpy as np
from pathlib import Path

# input Hads data folder
path = '/Volumes/vmfileshare/ClimateData/Interim/HadsUK/three.cities/'

# output Hads data folder - NOTE: this is a local path, please change to local or Azure path
path_output = '/debiasing_test/observation/'
# path_output = '/Volumes/vmfileshare/ClimateData/Interim/HadsUK/three.cities.greg/'

# do this for two variables - tasmin is omitted because dates in files are different
for variable in ["tasmax", "rainfall"]:

    # create a list of input and output files
    files_in = []
    files_in.extend([f for f in glob.glob(path + "**/*.tif", recursive=True)])
    files_in = [f for f in files_in if variable in f]
    files_out = [f"{'_'.join(f.split('_')[:-1])}-{f.split('_')[-1]}" for f in files_in]
    files_out = [f.replace("tif", "nc") for f in files_out]
    files_out = [f.replace("20091231", "20091230") for f in files_out]
    files_out = [f.replace("20191231", "20191230") for f in files_out]
    files_out = [f.replace("20100131", "20100130") for f in files_out]
    files_out = [f.replace("20200131", "20200130") for f in files_out]
    files_out = ["." + f.replace(path, path_output) for f in files_out]

    for i, file_in in enumerate(files_in):

        # these are the lower and upper indexes used to slice the arrays, which change depending on
        # whether we process the 1980-2010 or 2010-2020 Hads input
        lower_index, upper_index = (0, 10840) if "1980" in file_in else (720, 2890)

        # read the raster data (.tif)
        data = xr.open_dataset(file_in)

        # drop the five redundant dates for each leap year (approximate indexes are used)
        data = data.drop_sel(band=np.arange(lower_index + 59, upper_index, 1445).tolist())
        data = data.drop_sel(band=np.arange(lower_index + 120, upper_index, 1445).tolist())
        data = data.drop_sel(band=np.arange(lower_index + 211, upper_index, 1445).tolist())
        data = data.drop_sel(band=np.arange(lower_index + 271, upper_index, 1445).tolist())
        data = data.drop_sel(band=np.arange(lower_index + 334, upper_index, 1445).tolist())

        # create a 360-day time index based on the date range of the file
        file_out = os.path.basename(files_out[i]).split('_')
        start = file_out[-1].split('-')[0]
        stop = file_out[-1].split('-')[1].split('.')[0]
        time_index = xr.cftime_range(start, stop, freq='D', calendar='360_day', inclusive='both')

        # rename attributes and data and assign time index
        data = data.rename(
            {"x": "projection_x_coordinate", "y": "projection_y_coordinate", "band": "time", 'band_data': variable}) \
            .rio.write_crs('epsg:27700')
        data.coords['time'] = time_index

        if not os.path.exists(os.path.dirname(files_out[i])):
            folder_path = Path(os.path.dirname(files_out[i]))
            folder_path.mkdir(parents=True)

        # write to an .nc file
        data.to_netcdf(files_out[i])
