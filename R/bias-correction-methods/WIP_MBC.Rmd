---
title: "WIP MBC in R"
author: "Ruth C E Bowyer"
date: "`r format(Sys.Date())`"
output:
  github_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 0. About

Testing Bias Correction methods from the MBC package in R

- For univariate methods, just replicating for a subset the same methods applied in python
- For multivariate methods, will try on all geographical locations 

```{r libraries dd}
rm(list=ls())

library(MBC)
library(terra)
library(sf)
library(exactextractr)

#Loaded package versions
x <- c("MBC", "terra", "sf", "exactextractr")
lapply(x,packageVersion)

#Path is "/<mount location>/vmfileshare/ClimateData
#dd <- "/Volumes/vmfileshare/ClimateData/"
dd <- "/mnt/vmfileshare/ClimateData/"
```


## 1. Load Data

### Observational data

Reprojected HADs data 

Awaiting confirmation about this data - I believe the data in `Processed/HadsUKgrid/resampled_2.2km/tasmax/day/`is perhaps not for use? 

*Temp solution to get pipeline running*:

Going to crop extent of HADs grid to smaller region and run only on Scotland for time being 

```{r}
#fp <- "Processed/HadsUKgrid/resampled_2.2km_newgrid/tasmax/day/"
#f <- list.files(paste0(dd, fp))
#HADs <- rast(paste0(dd, fp,f))

f <- paste0(dd, "Raw/HadsUKgrid/tasmax/day/")
hads.tasmax <- list.files(f)

v <- c("tasmax", "tasmin","rainfall")
vd <- paste0(dd,"/Raw/HadsUKgrid/",v,"/day/")


HADs.files<- unlist(lapply(vd,list.files))

HADs.nc.files <- HADs.files[grepl("*.nc$", HADs.files)]  

Hads_raw_eg <- rast(paste0(vd[[1]], HADs.nc.files[[1]]))
Hads_raw_eg_r <- Hads_raw_eg$tasmax_7

# Rough bounding for NI
i <- rast()
ext(i) <- c(-0, 200000, 450000, 600000)
values(i) <- c(100)
 plot(Hads_raw_eg_r)
plot(i, add=T)
```

# HERE

Adding in script to resample just this cropped part, then crop corresponding UKCP data and apply the bias corrections! 

```{r}

##For recalibration, only need years 1980-2000 
##Updating to just be for one year because it keeps crashing out below 
##and this is being run to compare python methods
s <- paste0("day_", 2000, collapse="|")
HADs.nc.files.slice1 <- HADs.nc.files[grepl(s, HADs.nc.files)] 

#Nested list of variables by terra rasts - One SpatRaster for each year 

List.Rast <- lapply(v, function(x){
  v.files <- HADs.nc.files.slice1[grepl(x, HADs.nc.files.slice1)]
  v.files.d <- paste0(dd,"/Raw/HadsUKgrid/",x,"/day/",v.files)
  HADbrickL <- lapply(v.files.d, rast) #is a list of 240 bricks
  ##Each brick represents a month, with each raster layer within each brick representing the Hads grid for a day
  })

n.names <- paste0("HADbrickL_", v)
names(List.Rast) <- n.names

#### Create Grid from UKCP data 

#Extract the 2.2km grid from the UK raster and then overlay that and create the mean from HADs
## Random ukcp file for this 
f <- "/Volumes/vmfileshare/ClimateData/Processed/UKCP2.2_Reproj/tasmax_bng2/01/latest/tasmax_rcp85_land-cpm_uk_2.2km_01_day_19801201-19811130.tif"
r <- rast(f)
r <- r$`tasmax_rcp85_land-cpm_uk_2.2km_01_day_19801201-19811130_1`

# Resample -- Transfer values of a SpatRaster to another one with a different geometry
## Not run - lapply to run over all
#Resampled.HADs<- lapply(List.Rast, function(L){
 # lapply(L, function(x){
    #Bilinear resampling appropriate for continious vars 
  #terra::resample(x, r, method="bilinear", threads=TRUE)
  #  })
  #})

## Example for 17.50
x <- List.Rast$HADbrickL_tasmax[[1]]
y <- terra::resample(x, r, method="bilinear", threads=TRUE)


### Save output -- just for testing reasons going to save a geotiff and a netcd
writeRaster(y, "Resampled_HADs_tasmax.2000.01.tif")
saveRDS(y, "Resampled_HADs_tasmax.2000.01.RDS") 
```

```{r}
n <- names(UKCP_R2)[1:20]

# Returns a list of dataframes for each year by rows of the raster cells
ObsL <- lapply(n, function(i){
    Sp <- HADbrickL_crop_Y_2.2km360[[i]]
    Obs <- as(Sp, 'SpatialPolygonsDataFrame')
    Obs <- Obs@data
  })

#Reduce to one df
Obs_df <- ObsL %>% reduce(cbind)
Obs_oc <-  unlist(Obs_df)
```

##### Model outputs - calibration

```{r}
### Rename the Model years 
#First running on one run to test and then will loop
UKCP_R2 <- Lewisham.Bricks.AllYears$Run02

names(UKCP_R2) <- paste0("Y",c(1981:2000, 2021:2040, 2061:2080))

n <- names(UKCP_R2)[1:20]

# Returns a list of dataframes for each year by rows of the raster cells
CalL <- lapply(n, function(i){
    Sp <- UKCP_R2[[i]]
    Cal <- as(Sp, 'SpatialPolygonsDataFrame')
    Cal <- Cal@data
  })

#Reduce to one df
Cal_df <- CalL %>% reduce(cbind)
Cal_oc <- unlist(Cal_df)
```

##### Model outputs - projection

```{r}
### Rename the Model years 
#First running on one run to test and then will loop

n <- names(UKCP_R2)[21:60]

# Returns a list of dataframes for each year by rows of the raster cells
ProjL <- lapply(n, function(i){
    Sp <- UKCP_R2[[i]]
    Proj <- as(Sp, 'SpatialPolygonsDataFrame')
    Proj <- Proj@data
  })

#Reduce to one df
Proj_df <- ProjL %>% reduce(cbind)
Proj_oc <- unlist(Proj_df)
```


#### Univariate quantile mapping

This package for univar mapping but soon to be multivar

Following the vignette here (first using the test data) https://cran.r-project.org/web/packages/MBC/MBC.pdf 

Do this seperately for each run

Below method is univariate quanitle mapping

Next step multivariate mapping in same package 

```{r}
library(MBC)

# Univariate
  fit.qdm <- 
    QDM(o.c=Obs_oc, #vector of observed samples during the calibration period.
        m.c=Cal_oc, #vector of model outputs during the calibration period.
        m.p=Proj_oc, #vector of model outputs during the projected period.
        ratio=FALSE, #logical value indicating if samples are of a ratio quantity (e.g., precipitation) -- false as is temp
        trace=Inf) #numeric value indicating the threshold below which values of a ratio quantity (e.g., ratio=TRUE) should be considered exact zeros. -- need to read up on this 

  
mhat.c  <- fit.qdm$mhat.c
mhat.p   <- fit.qdm$mhat.p  
  
```

-- To do -- 

Next repopulate the dataframe as above, add back to the dataslots, and compare!
Then write in a loop
Then see how long it takes 
Then think about the next way of doing it