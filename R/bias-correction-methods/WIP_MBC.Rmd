---
title: "WIP MBC in R"
author: "Ruth C E Bowyer"
date: "`r format(Sys.Date())`"
output:
  github_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


## 0. About

Testing Bias Correction methods from the MBC package in R

Loading data as created in 'DataProcessingMBC.RMD' 

```{r libraries dd}
rm(list=ls())

library(MBC)
library(terra)
library(sf)
library(exactextractr)
library(reshape2) #melt
library(data.table) #for fread

#Loaded package versions
x <- c("MBC", "terra", "sf", "exactextractr")
lapply(x,packageVersion)

#Path is "/<mount location>/vmfileshare/ClimateData
#dd <- "/Volumes/vmfileshare/ClimateData/"
dd <- "/mnt/vmfileshare/ClimateData/"
```
## 1. Load data
```{r}

fp <- paste0(dd, "Interim/NI_cropped_MBCdata/")
files <- list.files(paste0(dd, "Interim/NI_cropped_MBCdata"))

#HADs grid observational data
obs <- files[grepl("HAD", files)]

obs.dfs <- lapply(obs, function(x){
  fread(paste0(fp, x))
})
names(obs.dfs) <- obs

#Using 1980 - 2010 as calibration period
cpm.files <- files[grepl("CPM", files)]
cal <- cpm.files[grepl("1980|2000", cpm.files)]

cal.dfs <- lapply(cal, function(x){
  fread(paste0(fp, x))
})
names(cal.dfs) <- cal

gc()
```

```{r}
#R crashed when reading all of this in so for now just doing the projections for the next few decades 
proj1 <- cpm.files[grepl("2020", cpm.files)]

proj.dfs <- lapply(proj1, function(x){
  fread(paste0(fp, x))
})

names(proj.dfs) <- proj1
```


## 2. Linear scaling

So the df is data as rows and cells as x - so need to t transform yours etc 

```{r}
library('qmap')
### QM1: Linear transform function

qm1.fit <- fitQmap(Obs, Mod.Hist, method = "PTF", transfun = "linear", wet.day =
FALSE, cost = "RSS") 
qm1.proj <- doQmapPTF(Mod.Hist, qm1.fit)
qm1.hist <- doQmapPTF(Mod.Proj, qm1.fit) 
```



## 3. Univariate quantile mapping

Following vignette here: https://cran.r-project.org/web/packages/MBC/MBC.pdf 

To really understand - is the distribution sampled from the whole data, or is it cell specific - as assume the former and then in which case the area will matter... 

Because its just asking for a vector, is it better to just loop it over by cell obs anyway?? or create a single vector

```{r}
#Start with tasmax

obs.tasmax <- as.data.frame(obs.dfs$HADsNI1980_2010_tasmax.2023.06.27.csv)
#Run 5
cal.tasmax_1 <- as.data.frame(cal.dfs$CPM_NI1980_1999tasmax_Run05.2023.06.27.csv)
cal.tasmax_2 <- as.data.frame(cal.dfs$CPM_NI2000_2009tasmax_Run05.2023.06.27.csv)
proj.tasmax <- as.data.frame(proj.dfs$CPM_NI2020_2039tasmax_Run05.2023.06.27.csv)


```


```{r}
library(MBC)

# Univariate
  fit.qdm <- 
    QDM(o.c=Obs_oc, #vector of observed samples during the calibration period.
        m.c=Cal_oc, #vector of model outputs during the calibration period.
        m.p=Proj_oc, #vector of model outputs during the projected period.
        ratio=FALSE, #logical value indicating if samples are of a ratio quantity (e.g., precipitation) -- false as is temp
        trace=Inf) #numeric value indicating the threshold below which values of a ratio quantity (e.g., ratio=TRUE) should be considered exact zeros. -- need to read up on this 

  
mhat.c  <- fit.qdm$mhat.c
mhat.p   <- fit.qdm$mhat.p  
  
```




### Multivariate quantile mapping 

-- To do -- 

Need to ensure can reproject data as spatial appropariately 
Assess methods - split sample approach etc