---
title: "WIP MBC in R"
author: "Ruth C E Bowyer"
date: "`r format(Sys.Date())`"
output:
  github_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 0. About

Testing Bias Correction methods from the MBC package in R

- For univariate methods, just replicating for a subset the same methods applied in python
- For multivariate methods, will try on all geographical locations 

```{r libraries dd}
rm(list=ls())

library(MBC)
library(terra)
library(sf)
library(exactextractr)
library(reshape2) #melt
library(foreach) #
library(doSNOW) #
library(doParallel) #
library(tidyverse) #

#Loaded package versions
x <- c("MBC", "terra", "sf", "exactextractr")
lapply(x,packageVersion)

#Path is "/<mount location>/vmfileshare/ClimateData
#dd <- "/Volumes/vmfileshare/ClimateData/"
dd <- "/mnt/vmfileshare/ClimateData/"
```

## 1. Load Data

To start with, cropping data to rough Northern Ireland extent

### Observational data

Reprojected HADs data located in `Processed/HadsUKgrid/resampled_2.2km/`  

```{r}
v <- c("tasmax", "tasmin","rainfall")
vd <- paste0(dd,"Processed/HadsUKgrid/resampled_2.2km/",v,"/day/")
HADs.files<- unlist(lapply(vd,list.files))

Hads_r_eg <- rast(paste0(vd[[1]], HADs.files[[1]]))
Hads_r_eg <- Hads_r_eg$tasmax_7

```


```{r}
	# Rough bounding for NI
i <- rast()
crs(i) <- crs(Hads_r_eg)
ext(i) <- c(-0, 190000, 450000, 600000)
values(i) <- c(100)

e <- ext(i)
NI.bbox <- as.polygons(e)

```

Using 1980 - 2010 for training, compare the BC applied to 2010 - 2021 to HADs grids 

This chunk: reads HADs obs in for each variable for year 2010-2021 and crops them to NI extent in parallel, then converts the data to a dataframe (input to MBC)
xy coords are kept to check alignment with CPM - **to be added** - inclusion of test data for this

```{r}

for(v in c("tasmax", "tasmin", "rainfall")){

  files <- HADs.files[grepl(v, HADs.files)] #Subset to run paths
  Runpaths <- paste0(dd,"Processed/HadsUKgrid/resampled_2.2km/",v,"/day/",files[1:360]) #Subsbetting to years 1980-2010

  i <- 2:length(Runpaths)
  
   # Read in 1st runpath as df with xy coords to ensure overlay with CPM data 
   p <- Runpaths[[1]] 
   r <- rast(p)
   r_c <- crop(r, NI.bbox) 
  rdf1 <- as.data.frame(r_c, xy=T) 
  
  # Load and convert remaining to single col dfs 
       dfL <-lapply(i, function(i){
          p <- Runpaths[[i]] 
                     r <- rast(p)
                     r_c <- crop(r, NI.bbox) 
                     rdf <- as.data.frame(r_c, xy=T) 
                     return(rdf)
       }) 

       df <- dfL %>% reduce(cbind)
       df <- cbind(rdf1, df)
       
      assign(paste0("HADsNI1980_2010_", v, ".df"), df)

  gc()
}  
  
```

To check at some point -- why is does tasmin have 11562 vars and the others have 11560 ?

```{r}

# Melt to long
HADsL <- list(HADsNI1980_2010_tasmax.df, HADsNI1980_2010_tasmin.df, HADsNI1980_2010_rainfall.df)

HADsLlong <- lapply(HADsL, function(l){
  melt <- melt(l, id=c("x","y"))
})

#HADsLlong.allvars <- HADsLlong %>% reduce(merge, by=c("x", "y"))

```


### CPM data

For now, loading - Run05, Run07, Run08, Run06


```{r}



```

##### Model outputs - calibration

```{r}
### Rename the Model years 
#First running on one run to test and then will loop
UKCP_R2 <- Lewisham.Bricks.AllYears$Run02

names(UKCP_R2) <- paste0("Y",c(1981:2000, 2021:2040, 2061:2080))

n <- names(UKCP_R2)[1:20]

# Returns a list of dataframes for each year by rows of the raster cells
CalL <- lapply(n, function(i){
    Sp <- UKCP_R2[[i]]
    Cal <- as(Sp, 'SpatialPolygonsDataFrame')
    Cal <- Cal@data
  })

#Reduce to one df
Cal_df <- CalL %>% reduce(cbind)
Cal_oc <- unlist(Cal_df)
```

##### Model outputs - projection

```{r}
### Rename the Model years 
#First running on one run to test and then will loop

n <- names(UKCP_R2)[21:60]

# Returns a list of dataframes for each year by rows of the raster cells
ProjL <- lapply(n, function(i){
    Sp <- UKCP_R2[[i]]
    Proj <- as(Sp, 'SpatialPolygonsDataFrame')
    Proj <- Proj@data
  })

#Reduce to one df
Proj_df <- ProjL %>% reduce(cbind)
Proj_oc <- unlist(Proj_df)
```


#### Univariate quantile mapping

This package for univar mapping but soon to be multivar

Following the vignette here (first using the test data) https://cran.r-project.org/web/packages/MBC/MBC.pdf 

Do this seperately for each run

Below method is univariate quanitle mapping

Next step multivariate mapping in same package 

```{r}
library(MBC)

# Univariate
  fit.qdm <- 
    QDM(o.c=Obs_oc, #vector of observed samples during the calibration period.
        m.c=Cal_oc, #vector of model outputs during the calibration period.
        m.p=Proj_oc, #vector of model outputs during the projected period.
        ratio=FALSE, #logical value indicating if samples are of a ratio quantity (e.g., precipitation) -- false as is temp
        trace=Inf) #numeric value indicating the threshold below which values of a ratio quantity (e.g., ratio=TRUE) should be considered exact zeros. -- need to read up on this 

  
mhat.c  <- fit.qdm$mhat.c
mhat.p   <- fit.qdm$mhat.p  
  
```

-- To do -- 

Next repopulate the dataframe as above, add back to the dataslots, and compare!
Then write in a loop
Then see how long it takes 
Then think about the next way of doing it