---
title: "WIP MBC in R"
author: "Ruth C E Bowyer"
date: "`r format(Sys.Date())`"
output:
  github_document

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## 0. About

Testing Bias Correction methods from the MBC package in R

- For univariate methods, just replicating for a subset the same methods applied in python
- For multivariate methods, will try on all geographical locations 

```{r libraries dd}
rm(list=ls())

library(MBC)
library(terra)
library(sf)
library(exactextractr)
library(reshape2) #melt
library(foreach) #
library(doSNOW) #
library(doParallel) #
library(tidyverse) #

#Loaded package versions
x <- c("MBC", "terra", "sf", "exactextractr")
lapply(x,packageVersion)

#Path is "/<mount location>/vmfileshare/ClimateData
#dd <- "/Volumes/vmfileshare/ClimateData/"
dd <- "/mnt/vmfileshare/ClimateData/"
```

## 00. Script Functions

Potentially for future add to a source script but for now here is fine

```{r defining functions}

# A function to read in specific runs, vars and years 

read_crop_df <- function(runs, #Character vector of selected runs
                         var, #Character vector of selected variables - this might need changing
                         fp, #filepath of where files are - eg paste0(dd, "Reprojected_infill/UKCP2.2/")
                         year1, #Numeric, first year of segment
                         year2, #Numeric, lastyear of segment
                         name1, #Character - first part of name to be assigned to the returned df- usually the model
                         crop, #logical
                         crop.area, #Polygon of area to crop to - any Spat obj accepted by terra::crop will work
                         cropname){ #Character - name of crop to be assigned to the returned df - usually the crop area

    runs <- runs 
    var <- var
    years <- paste0(year1:year2, "1201", collapse="|")
    
    if(crop == T){
      
      bbox <- crop.area

       for(i in runs){
          for(v in var){
             p <- paste0(fp, v, "/", i, "/latest/")
             files <- list.files(p)
             files <- files[!grepl("aux.xml", files)]
  
             files.y <- files[grepl(years, files)]# Historical timeslice 2 for calibration
             files.y.p <- paste0(p, files.y)
    
        # Read in 1st runpath as df with xy coords to ensure overlay 
              p1 <- files.y.p[[1]] 
              r <- rast(p1)
              r_c <- crop(r, bbox) 
              rdf1 <- as.data.frame(r_c, xy=T) 
  
        # Load and convert remaining to single col dfs 
            dfL <- lapply(2:length(files.y.p), function(i){
                  p <- files.y.p[[i]] 
                  r <- rast(p)
                  r_c <- crop(r, bbox) 
                  rdf <- as.data.frame(r_c) 
                  return(rdf)
                  }) 
        
       df <- dfL %>% reduce(cbind)
       df <- cbind(rdf1, df)
       
       assign(paste0(name1, "_", cropname, year1, "_", year2, v, "_Run", i), df, envir = .GlobalEnv)
    
      gc()
          }
       }
    } else { #for where no crop to be applied

       for(i in runs){
          for(v in var){
             p <- paste0(fp, v, "/", i, "/latest/")
             files <- list.files(p)
             files <- files[!grepl("aux.xml", files)]
  
             files.y <- files[grepl(years, files)]# Historical timeslice 2 for calibration
             files.y.p <- paste0(p, files.y)
    
        # Read in 1st runpath as df with xy coords to ensure overlay 
              p1 <- files.y.p[[1]] 
              r <- rast(p1)
              rdf1 <- as.data.frame(r_c, xy=T) 
  
        # Load and convert remaining to single col dfs 
            dfL <- lapply(2:length(files.y.p), function(i){
                  p <- files.y.p[[i]] 
                  r <- rast(p)
                  rdf <- as.data.frame(r_c) 
                  return(rdf)
                  }) 
        
       df <- dfL %>% reduce(cbind)
       df <- cbind(rdf1, df)

      assign(paste0(name1, "_", year1, "_", year2, v, "_Run", i, envir = .GlobalEnv), df)
    
      gc()
      }
    }
  }
}
   

write.csv.date <- function(x, y){
  date <- Sys.Date()
  date <- gsub("-", ".", date)
  fn <- y
  rd <- rd
  csvFileName <- paste(rd,"/",fn,".",date,".csv",sep="")
  write.csv(x, file=csvFileName)}
      
```


## 1. Load Data

To start with, cropping data to rough Northern Ireland extent

### Observational data

Reprojected HADs data located in `Processed/HadsUKgrid/resampled_2.2km/`  

```{r}
v <- c("tasmax", "tasmin","rainfall")
vd <- paste0(dd,"Processed/HadsUKgrid/resampled_2.2km/",v,"/day/")
HADs.files<- unlist(lapply(vd,list.files))

Hads_r_eg <- rast(paste0(vd[[1]], HADs.files[[1]]))
Hads_r_eg <- Hads_r_eg$tasmax_7

```


```{r}
	# Rough bounding for NI
i <- rast()
crs(i) <- crs(Hads_r_eg)
ext(i) <- c(-0, 190000, 450000, 600000)
values(i) <- c(100)

e <- ext(i)
NI.bbox <- as.polygons(e)
```

Using 1980 - 2010 for training, compare the BC applied to 2010 - 2021 to HADs grids 

This chunk: reads HADs obs in for each variable for year 2010-2021 and crops them to NI extent in parallel, then converts the data to a dataframe (input to MBC)
xy coords are kept to check alignment with CPM 

Have no updated the read_crop_df function to have this run on observational (requires adding another if... statement just for the run aspect of the CPM)

```{r}

for(v in c("tasmax", "tasmin", "rainfall")){

  files <- HADs.files[grepl(v, HADs.files)] #Subset to run paths
  Runpaths <- paste0(dd,"Processed/HadsUKgrid/resampled_2.2km/",v,"/day/",files[1:360]) #Subsetting to years 1980-2010

  i <- 2:length(Runpaths)
  
   # Read in 1st runpath as df with xy coords to ensure overlay with CPM data 
   p <- Runpaths[[1]] 
   r <- rast(p)
   r_c <- crop(r, NI.bbox) 
  rdf1 <- as.data.frame(r_c, xy=T) 
  
  # Load and convert remaining to single col dfs 
       dfL <-lapply(i, function(i){
          p <- Runpaths[[i]] 
                     r <- rast(p)
                     r_c <- crop(r, NI.bbox) 
                     rdf <- as.data.frame(r_c) 
                     return(rdf)
       }) 

       df <- dfL %>% reduce(cbind)
       df <- cbind(rdf1, df)
       
      assign(paste0("HADsNI1980_2010_", v, ".df"), df)

  gc()
}  
  
```


#### Write dfs 



```{r}

rd <- "~/Desktop/clim-recal/clim-recal/data/MBCdata"

wL <- list(HADsNI1980_2010_tasmax.df, HADsNI1980_2010_tasmin.df, HADsNI1980_2010_rainfall.df)
dfnames <- c("HADsNI1980_2010_tasmax", "HADsNI1980_2010_tasmin", "HADsNI1980_2010_rainfall")
names(wL) <- dfnames

lapply(dfnames, function(x){
  df <- wL[[x]]
  write.csv.date(df, x)
})
```

To check at some point -- why is does tasmin have 11562 vars and the others have 11560 ?

```{r}

# Melt to long
HADsL <- list(HADsNI1980_2010_tasmax.df, HADsNI1980_2010_tasmin.df, HADsNI1980_2010_rainfall.df)

HADsLlong <- lapply(HADsL, function(l){
  melt <- melt(l, id=c("x","y"))
  #Create an ID variable for easy merging
  melt$xy <- paste0(melt$x, "-",melt$y)
  return(melt)
})

```

```{r}
HADsLlong.allvars <- HADsLlong %>% reduce(cbind)

#Remove duplicate x and y - checking below with the xy variable all map ok
names(HADsLlong.allvars) <- c("x","y", "tasmax_iy", "tasmax", "xy1",
                              "x2", "y2", "tasmin_iy", "tasmin", "xy2",
                              "x3", "y3", "rainfall_iy", "rainfall", "xy3")

#Check all xy vars match
#table(HADsLlong.allvars$xy1 == HADsLlong.allvars$xy2)
#table(HADsLlong.allvars$xy1 == HADsLlong.allvars$xy3)

#All match so remove not needed variables
HADsLlong.allvars[c("x2", "y2", "xy2", "x3", "y3", "xy3")] <- NULL

```



### CPM data

For now, loading - Run05, Run07, Run08, Run06

Cropping all to NI for this first iteration  

**Note** - naming convention for precipitation - currently is 'rainfall' in HADs but maybe could change? 

#### Historical 

```{r CPM historical 1}

runs <- c("05", "07", "08", "06")
var <- c("tasmax", "tasmin","pr")

read_crop_df(runs=runs, var=var, fp=paste0(dd, "Reprojected/UKCP2.2/"),
              year1=1980, year2=1999, name1="CPM", crop = T, crop.area = NI.bbox, cropname = "NI")
```

```{r write hist CPM}
#When decided the format of all of the many dfs to be used, can reqrite the above function to return all as list rather than returning individual dfs to the environment
CPM.hist.L.all <- list(CPM_NI1980_1999pr_Run05, CPM_NI1980_1999pr_Run06, CPM_NI1980_1999pr_Run07, CPM_NI1980_1999pr_Run08,
                       CPM_NI1980_1999tasmax_Run05, CPM_NI1980_1999tasmax_Run06, CPM_NI1980_1999tasmax_Run07, CPM_NI1980_1999tasmax_Run08,
                       CPM_NI1980_1999tasmin_Run05, CPM_NI1980_1999tasmin_Run06, CPM_NI1980_1999tasmin_Run07, CPM_NI1980_1999tasmin_Run08)

names(CPM.hist.L.all) <- c("CPM_NI1980_1999pr_Run05", "CPM_NI1980_1999pr_Run06", "CPM_NI1980_1999pr_Run07", "CPM_NI1980_1999pr_Run08",
                       "CPM_NI1980_1999tasmax_Run05", "CPM_NI1980_1999tasmax_Run06", "CPM_NI1980_1999tasmax_Run07", "CPM_NI1980_1999tasmax_Run08",
                       "CPM_NI1980_1999tasmin_Run05", "CPM_NI1980_1999tasmin_Run06", "CPM_NI1980_1999tasmin_Run07", "CPM_NI1980_1999tasmin_Run08")


lapply(names(CPM.hist.L.all), function(x){
  df <- CPM.hist.L.all[[x]]
  write.csv.date(df, x)
})

```



#### Historical - infill

Using 2010-2020 as test period so just loading in 2000 - 2009 here 


```{r CPM historical 2}

read_crop_df(runs=runs, var=var, fp=paste0(dd, "Reprojected_infill/UKCP2.2/"),
              year1=2000, year2=2009, name1="CPM", crop = T, crop.area = NI.bbox, cropname = "NI")
```

```{r write hist CPM}
#When decided the format of all of the many dfs to be used, can reqrite the above function to return all as list rather than returning individual dfs to the environment
CPM.hist_infill.L.all <- list(CPM_NI2000_2009pr_Run05, CPM_NI2000_2009pr_Run06, CPM_NI2000_2009pr_Run07, CPM_NI2000_2009pr_Run08,
                       CPM_NI2000_2009tasmax_Run05, CPM_NI2000_2009tasmax_Run06, CPM_NI2000_2009tasmax_Run07, CPM_NI2000_2009tasmax_Run08,
                       CPM_NI2000_2009tasmin_Run05, CPM_NI2000_2009tasmin_Run06, CPM_NI2000_2009tasmin_Run07, CPM_NI2000_2009tasmin_Run08)

names(CPM.hist_infill.L.all) <- c("CPM_NI2000_2009pr_Run05", "CPM_NI2000_2009pr_Run06", "CPM_NI2000_2009pr_Run07", "CPM_NI2000_2009pr_Run08",
                       "CPM_NI2000_2009tasmax_Run05", "CPM_NI2000_2009tasmax_Run06", "CPM_NI2000_2009tasmax_Run07", "CPM_NI2000_2009tasmax_Run08",
                       "CPM_NI2000_2009tasmin_Run05", "CPM_NI2000_2009tasmin_Run06", "CPM_NI2000_2009tasmin_Run07", "CPM_NI2000_2009tasmin_Run08")


lapply(names(CPM.hist_infill.L.all), function(x){
  df <- CPM.hist_infill.L.all[[x]]
  write.csv.date(df, x)
})

```

#### Projections

##### 2020 - 2040

```{r CPM historical 1}

runs <- c("05", "07", "08", "06")
var <- c("tasmax", "tasmin","pr")

read_crop_df(runs=runs, var=var, fp=paste0(dd, "Reprojected/UKCP2.2/"),
              year1=2020, year2=2039, name1="CPM", crop = T, crop.area = NI.bbox, cropname = "NI")
```

```{r write hist CPM}
#When decided the format of all of the many dfs to be used, can reqrite the above function to return all as list rather than returning individual dfs to the environment
CPM20.39L.all <- list(CPM_NI2020_2039pr_Run05, CPM_NI2020_2039pr_Run06, CPM_NI2020_2039pr_Run07, CPM_NI2020_2039pr_Run08,
                       CPM_NI2020_2039tasmax_Run05, CPM_NI2020_2039tasmax_Run06, CPM_NI2020_2039tasmax_Run07, CPM_NI2020_2039tasmax_Run08,
                       CPM_NI2020_2039tasmin_Run05, CPM_NI2020_2039tasmin_Run06, CPM_NI2020_2039tasmin_Run07, CPM_NI2020_2039tasmin_Run08)

names(CPM20.39L.all) <- c("CPM_NI2020_2039pr_Run05", "CPM_NI2020_2039pr_Run06", "CPM_NI2020_2039pr_Run07", "CPM_NI2020_2039pr_Run08",
                       "CPM_NI2020_2039tasmax_Run05", "CPM_NI2020_2039tasmax_Run06", "CPM_NI2020_2039tasmax_Run07", "CPM_NI2020_2039tasmax_Run08",
                       "CPM_NI2020_2039tasmin_Run05", "CPM_NI2020_2039tasmin_Run06", "CPM_NI2020_2039tasmin_Run07", "CPM_NI2020_2039tasmin_Run08")


lapply(names(CPM20.39L.all), function(x){
  df <- CPM20.39L.all[[x]]
  write.csv.date(df, x)
})

```



There are many more cells in the CPM compared with the Hats data because the CPM includes Sea cells - merging by the x and y coordinates results in a merge of just the cells in both (no loss from the Hads dataset)


#HERE
Load later and infill CPM data -- after 2022 for both -- you need to clear everything then creat NI box and run again as Rstudio is getting overwhelmed 
merge where relevant - in loop - and run MBC!!


#OLD CODE

##### Model outputs - calibration

```{r}
### Rename the Model years 
#First running on one run to test and then will loop
UKCP_R2 <- Lewisham.Bricks.AllYears$Run02

names(UKCP_R2) <- paste0("Y",c(1981:2000, 2021:2040, 2061:2080))

n <- names(UKCP_R2)[1:20]

# Returns a list of dataframes for each year by rows of the raster cells
CalL <- lapply(n, function(i){
    Sp <- UKCP_R2[[i]]
    Cal <- as(Sp, 'SpatialPolygonsDataFrame')
    Cal <- Cal@data
  })

#Reduce to one df
Cal_df <- CalL %>% reduce(cbind)
Cal_oc <- unlist(Cal_df)
```

##### Model outputs - projection

```{r}
### Rename the Model years 
#First running on one run to test and then will loop

n <- names(UKCP_R2)[21:60]

# Returns a list of dataframes for each year by rows of the raster cells
ProjL <- lapply(n, function(i){
    Sp <- UKCP_R2[[i]]
    Proj <- as(Sp, 'SpatialPolygonsDataFrame')
    Proj <- Proj@data
  })

#Reduce to one df
Proj_df <- ProjL %>% reduce(cbind)
Proj_oc <- unlist(Proj_df)
```


#### Univariate quantile mapping

This package for univar mapping but soon to be multivar

Following the vignette here (first using the test data) https://cran.r-project.org/web/packages/MBC/MBC.pdf 

Do this seperately for each run

Below method is univariate quanitle mapping

Next step multivariate mapping in same package 

```{r}
library(MBC)

# Univariate
  fit.qdm <- 
    QDM(o.c=Obs_oc, #vector of observed samples during the calibration period.
        m.c=Cal_oc, #vector of model outputs during the calibration period.
        m.p=Proj_oc, #vector of model outputs during the projected period.
        ratio=FALSE, #logical value indicating if samples are of a ratio quantity (e.g., precipitation) -- false as is temp
        trace=Inf) #numeric value indicating the threshold below which values of a ratio quantity (e.g., ratio=TRUE) should be considered exact zeros. -- need to read up on this 

  
mhat.c  <- fit.qdm$mhat.c
mhat.p   <- fit.qdm$mhat.p  
  
```

-- To do -- 

Next repopulate the dataframe as above, add back to the dataslots, and compare!
Then write in a loop
Then see how long it takes 
Then think about the next way of doing it