---
title: "Assessing and Processing LCAT data"
author: "Ruth C E Bowyer"
date: "`r format(Sys.Date())`"
output:
  github_document
---



```{r libs and setup, message=FALSE, warning=F}
rm(list=ls())

knitr::opts_knit$set(root.dir="/mnt/vmfileshare/ClimateData/")

library(ggplot2)
library(terra)
library(tmap) #pretty maps
library(RColorBrewer)

dd <- "/mnt/vmfileshare/ClimateData/"

```


## **0. About**

LCAT require 'bias corrected' data for the whole of the UK. 
We have applied a widely used approach, quantile mapping, to the data. Specifically, we have used *non-parametric quantile mapping using empirical quantiles* as available in the `Qmap` package. 
Because the data is so large, we have applied this bias correction to the UK broked down into regions, with Scotland brokedn down into further regions (see `R/LCAT/Region.Refs.csv`)

We will now:

- Assess the bias correction using some of the segments
- Process the data back to geotiff 
- Either process as monthly data or as UK wide rasters (maybe just write them seperately) and av across runs

The data is within `ClimateData/Debiased/R/QuantileMapping` and is in RDS format, with each object containing a list.

The objects within this R list are as follows:
- 't.obs': transposed observation df
- 't.cal': transposed calibration df
- 't.proj': transposed projection df (included the validation period)
- 'qm1.hist.a' - bias corrected values for the historical period, values fitted with linear interpolation
- 'qm1.hist.b' - bias corrected values for the historical period, values fitted with tricubic interpolation
- 'qm1.proj.a' - bias corrected values for the validation/projection period, values fitted with linear interpolation
- 'qm1.proj.b' - bias corrected values for the validation/projection period, values fitted with tricubic interpolation

## **1. Bias Correction Assessment: trends**

### **London - tasmax = Run 08**

Using the London region (UKI) as this is the smallest -- not this is the same regional area as the 'three.cities' crops but cut to shapefile edges rather than the square grid 

```{r}

London <- readRDS(paste0(dd,"/Debiased/R/QuantileMapping/resultsLRun08_UKI_tasmax.RDS"))

```

Load in Hads validation data 
(So this can be run for all of the LCAT data, I'm going to read in the whole HADs files for the calibration years)

**The calibration period is 2009-12-01 to 2019-11-30 to relate to the CPM month grouping**

```{r}

fp <- "/mnt/vmfileshare/ClimateData/Processed/HadsUKgrid/resampled_2.2km/tasmax/day/"
hads.tasmax <- list.files(fp)
i <- grep("20091201-", hads.tasmax)
ii <- grep("20191130", hads.tasmax)
hads.tasmax.i <- hads.tasmax[i:ii]

source("/home/dyme/Desktop/clim-recal/clim-recal/R/misc/read_crop.fn.R")



```


### **1b. Check trends**

The next set of chunks visualise the data by converting back to raster, and by looking at the trends of data across all time periods

```{r convert to df and raster}

## Load a source raster to extract the crs
r <- list.files(paste0(dd, "Reprojected/UKCP2.2/tasmax/05/latest/"))
r <- r[1]
rp <- paste0(dd, "Reprojected/UKCP2.2/tasmax/05/latest/", r)
rast <- rast(rp)

crs <- crs(rast)

## Convert from matix to df, transpose, create x and y cols - when run in chunk this works fine but for some reason can throw an error when run otherwise
London.df <- lapply(London, 
                    function(x){
  df <- as.data.frame(t(x))
  rn <- row.names(df) #The x_y coords were saves as rownames
  x <- gsub("_.*", "", rn)
  y <- gsub(".*_", "", rn)
  xy <- data.frame(x=x,y=y)
  df <- cbind(xy,df)
  })

## Convert to rasters
London.rasts <- lapply(London.df, function(x){
  r <- rast(x, type="xyz")
  crs(r) <- crs
  return(r)
})


```

#### *Raster vis comparison*

Random selection of 3 days of the observation, calibration and two adjusted cals, for three historic days

```{r}
tm_shape(London.rasts$t.obs[[1]]) + tm_raster(title="Observation, 1980-12-01")
tm_shape(London.rasts$t.cal[[1]]) + tm_raster(title="Calibration, 1980-12-01")
tm_shape(London.rasts$qm1.hist.a[[1]]) + tm_raster(title="Calibration, bias corrected, linear 1980-12-01")
tm_shape(London.rasts$qm1.hist.b[[1]]) + tm_raster(title="Calibration, bias corrected, tricubic 1980-12-01")
```
#### *Annual trends - Calibration period - daily mean*

```{r}

London.dfg <- lapply(names(London.df), function(i){
  dfi <- London.df[[i]]
  x <- 3:ncol(dfi)
  
  dfx <- lapply(x, function(x){
    y <- dfi[,x]
    mean <- mean(y, na.rm=T)
    sd <- sd(y, na.rm=T)
    dfr <- data.frame(mean=mean, 
             sd.high=mean+sd,
             sd.low=mean-sd)
    names(dfr) <- paste0(i,".",names(dfr))
    dfr$day <- names(dfi)[x]
    return(dfr)
  })

  dfx_g <- dfx %>% purrr::reduce(rbind)
})

names(London.dfg) <- c("obs.daymeans", "raw.cal.daymeans",
                       "raw.proj.daymeans", "bc.a.cal.daymeans",
                       "bc.b.cal.daymeans", "bc.a.proj.daymeans",
                       "bc.b.proj.daymeans")

```

```{r}
#Add a day index to align the cal and obs 

London.dfg.calp <- London.dfg[c("obs.daymeans", "raw.cal.daymeans",
                       "bc.b.cal.daymeans", "bc.a.cal.daymeans")]

London.dfg.calp <- lapply(London.dfg.calp, function(x){
  x$dayi <- 1:nrow(x)
  x$day<- NULL
  return(x)
})

London.dfg.calp <- London.dfg.calp %>% reduce(merge, "dayi")

head(London.dfg.calp)
```

```{r}

London.dfg.calp_m <- reshape2::melt(London.dfg.calp, id="dayi") #create long df for plotting multiple lines

London.dfg.calp_mm <- London.dfg.calp_m[grepl(".mean", London.dfg.calp_m$variable),] #For easy vis, only keep mean vals
```


```{r Historic trend 1}

ggplot(London.dfg.calp_mm, aes(dayi, value, group=variable, colour=variable)) + 
  geom_line() +
  theme_bw() + ylab("Av daily max temp oC") + 
  ggtitle("Tasmax Hisotric trends") +
 scale_x_discrete(labels = NULL, breaks = NULL) + xlab("Day, 1980.12.01 - 2009.12.01") +
  scale_color_brewer(palette="Set1", name="Model", labels=c("Obs (Hads)", "Raw CPM", "BC CPM 1", "BC CPM 2"))

```

#### *Annual trends - Calibration period - seasonal mean*

Annotate season based on month index - the dates have different formats depending on the input data (ie hads vs cpm) so am pulling out the necessary to adjust sep 

```{r}

#Hads/obs df
obs.daymeans.df <- London.dfg$obs.daymeans

x <- obs.daymeans.df$day
obs.daymeans.df$season <- ifelse(grepl("1231_|0131_|0228_|0229_", x), "Winter",
                      ifelse(grepl("0331_|0430_|0531_", x), "Spring",
                          ifelse(grepl("0630_|0731_|0831_", x), "Summer", "Autumn")))

#A note here - the seasons should each have 90 days but seemingly Winter and Autumn have 89 and Spring and Summer have 91 - this is due to how the manual aligning worked out and should be updated when the hads data is re-run 


# Mutate to a seasonal mean
obs.seasonal.mean.df <- obs.daymeans.df %>% 
  group_by(season_year) %>% 
          mutate(mean.seasonal = mean(t.obs.mean),
                                    sd.high.seasonal = mean.seasonal + sd(t.obs.mean),
                                    sd.low.seasonal = mean.seasonal - sd(t.obs.mean))

obs.seasonal.mean.df <- obs.seasonal.mean.df %>%
  dplyr::select(season_year:sd.low.seasonal) %>% distinct()

#Grouping variable for later vars 
obs.seasonal.mean.df$model <- "obs"
```

```{r}
#lapply needs to needed 

London.dfg[c("raw.cal.daymeans", "bc.b.cal.daymeans", "bc.a.cal.daymeans")]

#lapply for remaining dfs
  x <- df$day
  #The CPM days are consecutive 1 - 360 by year
  winter <- paste0(30, "_", 1:90, collapse="|")
  spring <- paste0(30, "_", 91:180, collapse="|")
  summer <- paste0(30, "_", 181:270, collapse="|")
```
#HERE - sorting out below season
```{r}
  df$season <- ifelse(grepl(winter, x), "Winter",
                      ifelse(grepl(spring, x), "Spring",
                          ifelse(grepl(summer, x), "Summer", "Autumn")))

# Mutate to a seasonal mean
obs.seasonal.mean.df <- obs.daymeans.df %>% 
  group_by(season_year) %>% 
          mutate(mean.seasonal = mean(t.obs.mean),
                                    sd.high.seasonal = mean.seasonal + sd(t.obs.mean),
                                    sd.low.seasonal = mean.seasonal - sd(t.obs.mean))

obs.seasonal.mean.df <- obs.seasonal.mean.df %>%
  dplyr::select(season_year:sd.low.seasonal) %>% distinct()


obs.seasonal.mean.df$model <- "obs"
```


```{r Raw trend seasonal}

#Add in missing years for clearer plotting of trend
dfg_sm <- seasonal.mean

seas.miss <- rep(c("Spring", "Summer", "Autumn", "Winter"), 19)
year.miss <- rep(2041:2059, each=4)

add.s.y <- paste0(seas.miss, "_", year.miss)
add.s.y <- c("Winter_2040", add.s.y)

dfg_sm <- plyr::rbind.fill(dfg_sm,
                           data.frame(year=c(2040, year.miss),
                                      season_year=add.s.y, 
                                      mean.seasonal=NA,
                                      sd.low.seasonal=NA,
                                      sd.high.seasonal=NA))

dfg_sm <- dfg_sm[order(dfg_sm$year),]
```


**'Raw' - seasonal**

```{r Raw seasonal}

ggplot(dfg_sm) + 
  geom_ribbon(aes(x = 1:length(season_year), ymin = sd.low.seasonal, ymax=sd.high.seasonal), color="lightgrey", alpha=0.5) +
  geom_line(aes(x=1:length(season_year), y=mean.seasonal), color="cornflowerblue", group=1) +
  theme_bw() + ylab("Av daily max temp oC") + 
  ggtitle("'Raw' - tasmax seasonal") + 
  xlab("Season - Year") +
  scale_x_discrete(labels = c(dfg_sm$season_year)) + 
  theme(axis.text.x = element_text(angle = 270, vjust = 0.5, hjust=1))

```


**'Raw' - Winter only**

```{r Raw seasonal winter}

dfg_sm_w <- subset(dfg_sm, grepl("Winter", season_year))

ggplot(dfg_sm_w) + 
  geom_ribbon(aes(year, ymin = sd.low.seasonal, ymax=sd.high.seasonal), 
              fill="lightblue3", alpha=0.5) +
  geom_line(aes(year, y=mean.seasonal), color="lightblue4", group=1) +
  theme_bw() + ylab("Av daily max temp oC") + 
  ggtitle("'Raw' - tasmax seasonal - Winter only") + 
  xlab("Year") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```


**'Raw' - Summer only**

```{r Raw seasonal summer}

dfg_sm_s <- subset(dfg_sm, grepl("Summer", season_year))

ggplot(dfg_sm_s) + 
  geom_ribbon(aes(year, ymin = sd.low.seasonal, ymax=sd.high.seasonal), 
              fill="darkgoldenrod", alpha=0.5) +
  geom_line(aes(year, y=mean.seasonal), color="darkred", group=1) +
  theme_bw() + ylab("Av daily max temp oC") + 
  ggtitle("'Raw' - tasmax seasonal - Summer only") + 
  xlab("Year") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

```

#### *Annual trends - seasonal max*

I think visualising the daily data is not mega helpful, but now grouping to season and calculating the seasonal maxima vals (i.e. rather than means above)

#### *Validation period - annual trends - seasonal mean*

#### *Validation period - annual trends - seasonal max*


## **2. Bias Correction Assessment: Metrics**

Add in HADs data from the cal period 

### mean by cell 
