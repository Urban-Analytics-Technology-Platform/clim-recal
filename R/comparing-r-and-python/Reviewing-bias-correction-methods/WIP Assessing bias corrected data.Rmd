---
title: "WIP Assessing bias corrected data"
author: "Ruth C E Bowyer"
output: 
  github_document:
    keep_html: true
  html_document:
    theme: cosmo
    toc: TRUE
    toc_float: TRUE
    toc_depth: 4
    df_print: paged
  date: "`r format(Sys.Date())`"
---

```{r libs and setup, message=FALSE, warning=F}
rm(list=ls())

knitr::opts_knit$set(root.dir="/Volumes/vmfileshare/ClimateData/")

library(terra)
library(sp)
library(exactextractr)

dd <- "/Volumes/vmfileshare/ClimateData/"

```


## **0. About**

Assessing the bias correction applied using the ```cmethods``` package. 

## **0. Raw data**

Comparing to the 'Raw' (but reprojecte CPM data) 

```{r load raw data}
# Read in as list of quantile mapping data
## Each decade is seperated out - but potential should we brick these together?
p <- paste0(dd, "Reprojected/UKCP2.2/tasmax/01/latest/")
files <- list.files(p)

raw.files <- files[!grepl("aux.xml", files)]
raw.files.p <- paste0(p, raw.files)
raw.dat <- lapply(raw.files.p, rast) 

#Crop to Scotland extent 
scot <- vect("~/Library/CloudStorage/OneDrive-TheAlanTuringInstitute/CLIM-RECAL/clim-recal/data/Scotland/Scotland.bbox.shp")

raw.dat_c <- lapply(raw.dat, function(i){ crop(i, scot) })

raw.dat_r <- rast(raw.dat_c)
```



##**1. Bias corrected data **

Load and check files 

```{r load data 1}

# Each method is a sep file per decade 
# Create a character vector listing the methods 

p <- paste0(dd, "Debiased/tasmax/")
f <- list.files(p)
i <- c("debiased_delta_method_result", "debiased_linear_scaling_result", "debiased_quantile_delta_mapping", "debiased_quantile_mapping", "debiased_variance_scaling")

# Returns a list of stacked rasters (one for each method) 
debiased_data <- lapply(i, function(x){
  files <- f[grepl(x, f)]
  files.p <- paste0(p, files)
  #Reads in as list of Rasters 
  dat <- lapply(files.p, rast) 
  #Load all together so one raster per method
  files.r <- rast(dat)
})

names(debiased_data) <- i

```

## **2. Assessing the bias correction methods**

### **2a. Time series**

Check the time series over the whole dataset makes sense

#### **2ai. Delta method**

**cemthods** implements Delta Method based on: Beyer, R. and Krapp, M. and Manica, A.: An empirical evaluation of bias correction methods for palaeoclimate simulations (https://doi.org/10.5194/cp-16-1493-2020), which describes the methods as follows:

*The delta method consists of adding the difference between past and present-day simulated climate to present-day observed climate. As such, the delta method assumes that local (i.e. grid-cell-specific) model biases are constant over time (Maraun and Widmann, 2018). For temperature variables (including terrestrial and marine mean annual temperatures and terrestrial temperature of the warmest and coldest months considered here), the bias in a geographical location x is given by the difference between present-day observed and simulated temperature ...

Precipitation is bounded below by zero and covers different orders of magnitude across different regions. A multiplicative rather than additive bias correction is therefore more common when applying the delta method for precipitation, which corresponds to applying the simulated relative change to the observations (Maraun and Widmann, 2018).*


```{r}
delta <- debiased_data$debiased_delta_method_result
nlyr(delta) #14400 -  correct number for 40Y * (12m*30d) - ie 14400 days
#Check crop and map
plot(delta[1])

```



